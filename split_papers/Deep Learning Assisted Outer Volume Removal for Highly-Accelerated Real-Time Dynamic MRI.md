<|startofpaper|>
## Deep Learning Assisted Outer Volume Removal for Highly-Accelerated Real-Time Dynamic MRI

Merve G¨ ulle ab , Sebastian Weing¨rtner a cd , Mehmet Ak¸ cakaya ab ∗ a Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, United States b Center for Magnetic Resonance Research, University of Minnesota, Minneapolis, MN, United States c Department of Imaging Physics, Delft University of Technology, Delft, the Netherlands d

HollandPTC, Delft, the Netherlands

∗ Corresponding author: Mehmet Ak¸ cakaya; akcakaya@umn.edu

## Abstract

Real-time (RT) dynamic MRI plays a vital role in capturing rapid physiological processes, offering unique insights into organ motion and function. Among these applications, RT cine MRI is particularly important for functional assessment of the heart with high temporal resolution. RT imaging enables free-breathing, ungated imaging of cardiac motion, making it a crucial alternative for patients who cannot tolerate conventional breath-hold, ECG-gated acquisitions. However, achieving high acceleration rates in RT cine MRI is challenging due to aliasing artifacts from extra-cardiac tissues, particularly at high undersampling factors. In this study, we propose a novel outer volume removal (OVR) method to address this challenge by eliminating aliasing contributions from non-cardiac regions in a post-processing framework. Our approach estimates the outer volume signal for each timeframe using composite temporal images from time-interleaved undersampling patterns, which inherently contain pseudo-periodic ghosting artifacts. A deep learning (DL) model is trained to identify and remove these artifacts, producing a clean outer volume estimate that is subsequently subtracted from the corresponding k-space data. The final reconstruction is performed with a physics-driven DL (PD-DL) method trained using an OVR-specific loss function to restore high spatio-temporal resolution images. Experimental results show that the proposed method at high accelerations achieves image quality that is visually comparable to clinical baseline images, while outperforming conventional reconstruction techniques, both qualitatively and quantitatively. The proposed approach provides a practical and effective solution for artifact reduction in RT cine MRI without requiring acquisition modifications, offering a pathway to higher acceleration rates while preserving diagnostic quality.

Keywords: Real-time MRI; Dynamic MRI; Cine CMR; Ghosting artifacts; Outer volume removal; Unrolled networks; DL-based reconstruction

## 1 Introduction

Real-time (RT) dynamic MRI facilitates visualization of physiological changes in real-time, using rapid snapshot acquisitions (Nayak et al., 2022). These acquisitions are particularly useful for capturing non-periodic processes, where conventional gating or averaging methods may fail (Nayak et al., 2022). Such acquisitions are important in diverse clinical applications, ranging from assessment of cardiac function (X. Wang et al., 2021; S. Zhang et al., 2014) to guidance of interventional procedures (Chubb et al., 2017; Van den Bosch et al., 2008) to upper airway imaging (Lingala et al., 2016; Zu et al., 2013) to musculoskeletal applications (Kawchuk et al., 2015). Among these, real-time cine cardiac MRI (CMR) is commonly used clinically as an alternative to breath-hold (BH) segmented cine CMR (Long` ere et al., 2023; X. Wang et al., 2021). The latter is considered the gold standard imaging technique for functional evaluation of the heart and is acquired with electrocardiogram (ECG) gating in BH to minimize motion artifacts and enhance image clarity (Ishida et al., 2009). However, this method poses significant challenges for patients with arrhythmia, and for those who are unable to hold their breath, such as young children or individuals with respiratory issues (Roy et al., 2022), making the acquisition process difficult and often leading to suboptimal image quality (Rajiah et al., 2023). For these patients, RT cine CMR is essential to allow free-breathing imaging without the need for ECG synchronization (Beer et al., 2010; Nayak et al., 2022). RT cine CMR acquires dynamic images of the heart in succession using snapshot imaging, accommodating irregular heartbeats and breathing, which are critical in cases where traditional BH and ECG-gated protocols are

not feasible (Unterberg-Buchwald et al., 2014). High spatio-temporal resolution for RT cine CMR is crucial to accurately capture rapid cardiac motion and detailed anatomical structures (Setser et al., 2000).

Current RT CMR techniques often utilize parallel imaging (Breuer et al., 2005; Kellman et al., 2001) and compressed sensing (Feng et al., 2011; Jung et al., 2009; Otazo et al., 2010) to accelerate MRI scans. While these techniques have shown advancements in reducing scan times and improving image quality, they face challenges in achieving adequate spatio-temporal resolution for dynamic cardiac imaging due to the low acceleration rates (Jung et al., 2009; Li et al., 2018; Tolouee et al., 2018). On the other hand, some studies employ spatio-temporal regularization techniques during the reconstruction process (Demirel, Zhang, et al., 2023; Feng et al., 2016; Hansen et al., 2012; Hauptmann et al., 2019; Liu et al., 2020; Otazo et al., 2015; Pedersen et al., 2009; Tsao et al., 2003). These techniques reduce artifacts by leveraging the underlying spatial and temporal correlations but can introduce risks of temporal blurring, despite the critical importance of preserving sharp temporal features in dynamic cardiac imaging (Najeeb et al., 2020). Thus, novel reconstruction techniques that enable high acceleration rates without requiring temporal regularization are desirable for RT CMR.

A major challenge in achieving higher acceleration rates for RT CMR using current techniques is related to the large amount of outer volume tissue that surrounds the heart (Smith &amp; Nayak, 2012). When imaging the heart, a large field of view (FOV), including areas such as the chest and back, is prescribed to avoid foldover. These outer volume tissues contain high-intensity fat signals, which contribute to high-intensity aliasing artifacts in the region of interest (ROI) encompassing the heart. At high acceleration rates, these present substantial challenges during reconstruction, potentially degrading image quality (Griswold et al., 2004). To address this challenge in broader cardiac MRI applications, one strategy involves the use of outer volume suppression (OVS) pulses or modules (Coristine et al., 2015; Luo et al., 2015; Smith &amp; Nayak, 2012; J. Wang et al., 2021; Weing¨rtner et a al., 2018; Yang et al., 2018). These techniques aim to selectively suppress signals from surrounding extra-cardiac tissues that could otherwise degrade image quality. However, acquisitions that incorporate OVS modules have downsides, including signal recovery during imaging, high specific absorption rates (SAR), imperfect suppression, and importantly, disruptions to steady-state imaging, which limits its use in acquisitions such as cine CMR. As an alternative, view-sharing or keyhole techniques have been proposed in an attempt to capture moving parts in a larger ROI (Fan et al., 2024; G´mez-Talavera et al., 2021). o These techniques acquire k-space data with different sub-sampling patterns, and share information across dynamics, and have also been combined with outer volume estimation (G´mez-Talavera et al., 2021). o However, their adoption in clinical practice has been limited due to residual temporal artifacts and challenges in accurately estimating extra-cardiac volumes.

In this study, we take a different approach by proposing a reconstruction method that removes extra-cardiac tissue signals during the post-processing stage. This technique simplifies the reconstruction problem by significantly reducing aliasing artifacts within the ROI. Importantly, it is applicable to existing acquisition schemes and avoids issues associated with signal regrowth commonly encountered in OVS-based acquisitions. The proposed outer volume removal (OVR) method first estimates the outer volume signal for each timeframe using composite temporal images from time-interleaved shifted dynamic acquisitions. While these composite images tend to exhibit ghosting artifacts due to motion, a deep learning (DL) model is used to estimate and remove these artifacts. The estimated outer volume signal is subsequently removed from the corresponding k-space raw data of each timeframe. Finally, a physics-driven DL (PD-DL) network is trained with an OVR-specific loss function to reconstruct this high temporal resolution data in a frame-by-frame manner. Our results show that the proposed method outperforms conventional methods and PD-DL reconstruction without OVR both qualitatively and quantitatively. Our contributions are as follows:

- · We introduce a novel analytical characterization for the pseudo-periodic ghosting artifacts observed in lowtemporal resolution composite images formed from time-interleaved shifted undersampling patterns, not considered in the literature before.
- · We propose a DL-based strategy to robustly estimate these motion-induced ghosting artifacts from composite images, which is used to generate a clean estimate of the outer volume signal that is subsequently removed from each individual timeframe.
- · We propose a novel OVR-augmented loss function for training the PD-DL reconstruction network with improved fidelity, by promoting consistency between outputs corresponding to forward operators comprising coil sensitivities that span the whole FOV versus those that are constrained to the ROI.
- · We conduct extensive experiments across different field strengths using both retrospective and prospective accelerated datasets and demonstrate that our method outperforms conventional and state-of-the-art acceleration methods without OVR qualitatively and quantitatively.

## 2 Characterization of motion-induced ghosting in outer volume estimation

Let x ( ) t ∈ C N represent the t th complex-valued timeframe of a dynamic MRI sequence, where N is the number of pixels in the spatial plane, which is assumed to be 2D without loss of generality. The acquired k-space data, denoted as y Ω t ( ) t ∈ C M , corresponds to the measurements from k-space locations Ω , with t M being the number

Figure 1: Illustration of the decomposition of a composite real-time cine cardiac MR image into various components. For simpler visualization, the heart is depicted as the only moving object, while surrounding tissues are treated as stationary, and R = 4 is used. Both the moving components and stationary components of each time-frame contribute to the composite image as foldovers with distinct modulation coefficients due to the shifted phase encoding lines across time-frames. The moving components add constructively at the true heart location, creating a temporally averaged representation, while their summation at the other foldover locations leads to a pseudo-periodic ghosting artifact due to cardiac motion between time-frames and the distinct modulation coefficients. Conversely, the stationary components add constructively at the central foldover while canceling out at the other foldover locations.

<!-- image -->

of acquired k-space points per timeframe. Using a time-interleaved shifted equidistant or uniform undersampling pattern, as implemented in TGRAPPA (Breuer et al., 2005) or TSENSE (Kellman et al., 2001), one can generate a fully sampled composite k-space or image with low temporal resolution by combining R consecutive timeframes into a single merged dataset for acceleration rate R . Previous studies (Blaimer et al., 2008; G´mez-Talavera et o al., 2021) have utilized this composite data to estimate the stationary background by masking the background image. However, residual temporal artifacts have remained a major challenge in these approaches.

In this study, we propose a novel analytical perspective on such composite data by treating the images from each timeframe as a combination of moving, x moving ( ), and stationary. t x stationary ( ) components as: t

$$x ( t ) = x _ { \text{moving} } ( t ) + x _ { \text{stationary} } ( t ).$$

Fig. 1 illustrates this decomposition across different timeframes, where for simplicity, we depict the heart as the only moving object, while the surrounding tissues are considered stationary across these timeframes. For RT sequences, these assumptions approximately hold over the acquisition of R subsequent frames, provided the temporal resolution is sufficiently small, since the respiratory motion is much slower compared to cardiac motion. In this scenario, each individual timeframe contributes an aliased image of the heart and the stationary background to the composite image. Importantly, due to the time-interleaved shifted pattern in the k-space acquisitions, each foldover of the aliased components has a distinct modulation phase. In the composite image, the side foldovers of the aliased background tend to cancel each other out, resulting in a stationary background. Conversely, the foldovers of the aliased heart images align at the true heart location, forming a temporally averaged representation of the heart at its correct position. Finally, other foldovers of the moving components add up to produce ghosting artifacts in the background due to differing modulation phases, which manifests as a pseudo-periodic pattern.

Overall, this formulation allows us to decompose the composite image into the combination of temporarily averaged moving components x moving ( ), t a pseudo-periodic ghosting artifact x ghost ( ) t due to the moving tissue components, and a stationary background x stationary ( ) as: t

$$x _ { \text{com} } ( t ) = \underbrace { \overline { x } _ { \text{moving} } ( t ) + x _ { \text{ghost} } ( t ) } _ { \text{moving components} } + \underbrace { x _ { \text{stationary components} } } _ { \text{stationary components} }.$$

Figure 2: Importance of accounting for ghosting artifacts during OVR. (a) TGRAPPA reconstruction at acceleration rate R = 4. (b) CG-SENSE reconstruction of OVR k-space data at R = 4, using composite coil images as the outer volume, without ghosting artifact correction. (c) CG-SENSE reconstruction of OVR k-space data at R = 4, where the outer volume is estimated after ghosting artifact removal from composite images. The left column shows the baseline image during systole. The reconstruction of the same data in the middle column shows temporal blurring, effectively yielding a different cardiac phase due to the effect of the ghosting artifacts present in the data, while also exhibiting blurring artifacts. The right column matches the correct cardiac phase and shows high image fidelity.

<!-- image -->

Identifying and removing these ghosting artifacts is of paramount importance to maintain the temporal fidelity of the reconstructions after OVR. Fig. 2 illustrates reconstructions with outer volume subtraction, where the outer volume is estimated from the composite images directly without accounting for the ghosting artifacts, and using our approach that identifies and removes these ghosting artifacts. The baseline data, shown in the left column, is selected from a systolic cardiac phase and presents the TGRAPPA reconstruction of the R = 4 k-space data. In the middle column, a naive outer volume subtraction approach that uses the outer volume directly from the composite image is shown. The right column shows outer volume subtraction, where the ghosting artifacts are removed from the composite image prior to estimating the outer volume. The OVR k-space signal is calculated accordingly (explained in Sec. 3.1) and reconstructed with CGSENSE. The reconstruction with the naive outer volume estimation loses temporal fidelity since the ghosting artifacts from other cardiac phases affect the final reconstruction. As a result, cardiac phase mismatch and significant blurring are observed. On the other hand, the outer volume estimation that explicitly considers ghosting artifacts yields a reconstruction that aligns with the correct cardiac phase and maintains superior temporal fidelity.

We note that in contrast to the simplified depiction in Fig. 1, not only the heart but also other nearby tissues, such as the diaphragm, move rapidly enough to contribute to such ghosting artifacts. Consequently, while we use this simplified version in our preliminary work (G¨lle &amp; Ak¸ cakaya, 2024) and for illustrative purposes here, u our implementations in this study capture these three components without explicitly delineating boundaries for moving organs, as further described in Sec. 3.1.

## 3 Methods

## 3.1 DL-based ghosting detection and outer volume removal (OVR)

Let x com ( t 0 ) be the composite image of time t 0 . To estimate the background of this acquisition x background ( t 0 ), we first propose a DL-based technique to estimate the motion-related pseudo-periodic ghosting artifacts in the composite images illustrated in Fig. 3a. The network takes 4 adjacent composite images in channel-wise concatenated form, represented as x concat com ( t 0 ) ≜ { x com ( τ ) } t 0 +1 τ = t 0 -2 , covering a wider temporal window to leverage the correlation over timeframes. The network outputs the corresponding ghosting artifacts of each composite image in the output, again in a channel-wise concatenated form x concat ghost ( ) t ≜ { x ghost ( τ ) } t 0 +1 τ = t 0 -2 . We note that all four images are used for loss calculation, but only the ghosting estimate at t 0 is used for subsequent OVR for the corresponding timeframe.

The network is trained in a supervised manner by minimizing a normalized ℓ 2 loss between the network output and the reference ghosting artifacts

$$\min _ { \theta } \mathbb { E } \left [ \mathcal { L } _ { \text{normalized-} \ell _ { 2 } } \left ( x _ { \text{ghost-ref} } ^ { \text{concat} } ( t ), f _ { \theta } \left ( x _ { \text{com} } ^ { \text{concat} } ( t ) \right ) \right ],$$

Figure 3: Proposed reconstruction pipeline: (a) DL-based ghosting detection: A ResNet with 15 residual blocks (RBs) takes four adjacent composite images, concatenating their real and imaginary components into eight input channels (C in = 8), and estimates the ghosting artifacts for the corresponding time frame t 0 , producing eight output channels (C out = 8). The stationary background coil images, x background , are then obtained by subtracting the detected ghosting artifacts from the composite images of the target time frame. (b) Physics-driven DL-based unrolled network: The network consists of 35 unrolls, where each iteration block contains one ResNet and one data fidelity (DF) block. The ResNets (C in = 2, C out = 2, 15 residual blocks) perform the proximal operation for the regularizer on the previous DF block output, and share the same network weights ( θ ). The DF block takes the zerofilled image ( x 0 ), the last ResNet output ( z k ), sensitivity maps, and the acceleration mask, producing a data-consistent image as output using conjugate gradient. (c) The ResNet structure is used in both the ghosting detection network and the proximal operators of the unrolled network. (d) Outer volume subtraction and PD-DL reconstruction: The background image is masked using the OVR mask ( m OVR ) and transformed into k-space via the Fourier transform ( F Ω t ), then subtracted from the acquired signal ( y Ω t ). The OVR k-space signal y Ω t OVR is mapped back to the image domain using the adjoint encoding operator ( E Ω t ) H and fed into the unrolled network. As expected, the network output exhibits minimal background signal. (e) Final image formation by combining the masked background with the reconstruction.

<!-- image -->

where x concat ghost-ref ( ) is the concatenated reference ghosting images, the generation of which is detailed in Sec. t 4.2.1, and f θ ( ) is · the ghosting detection network with trainable parameters θ . After the estimation of these ghosting artifacts, their contribution is subtracted from the corresponding composite images to obtain clean outer volume background images:

$$\Phi _ { 0 } \quad \mathbf x _ { \text{background} } ( t _ { 0 } ) & \approx \mathbf x _ { \text{com} } ( t _ { 0 } ) - f _ { \theta } \left ( \mathbf x _ { \text{com} } ^ { \text{ concat} } ( t _ { 0 } ) \right ) \Big | _ { t = t _ { 0 } }$$

where f θ ( x i concat com ( t 0 ) ) ∣ ∣ t = t 0 refers to the estimated ghosting artifact of the time of interest t 0 over the four timeframes output by the neural network.

Finally, once the background signal is estimated according to (4), the last step for OVR is to subtract it from the raw k-space data without interfering with the signal around the heart. To this end, an additional neural network was trained to predict heart boundaries from coil-combined composite images. This was used to generate a mask, m OVR , that outlines the outer volume to be removed. The outer volume was defined as everything outside the heart boundaries. These boundaries were specified using a rectangle in the phase-encode direction, spanning the full frequency-encode direction (since no undersampling is performed in the latter), as illustrated in Fig. 3d.

<!-- image -->

Figure 4: PD-DL reconstruction of the OVR k-space using (a) masked sensitivity maps, (b) full sensitivity maps, and (c) full sensitivity maps with consistency through the proposed loss function in (8). The left column shows artifacts, while the middle column exhibits signal loss. The proposed consistency mechanism effectively mitigates both issues, as demonstrated in the right column.

<!-- image -->

<!-- image -->

Subsequently, the OVR k-space was generated from the acquired data y Ω t as:

$$y _ { O V R } ^ { \Omega _ { t } } = y ^ { \Omega _ { t } } - \mathcal { F } ^ { \Omega _ { t } } \{ \mathbf m _ { O V R } \cdot x _ { \text{background} } \},$$

where F Ω t denotes the Fourier transform operator undersampled at Ω t k-space locations. The DL-based generation of OVR masks and network details are described in Sec. 4.2.2.

## 3.2 PD-DL MRI reconstruction

Let y Ω t OVR be the outer volume-removed k-space signal with Ω t as the undersampling pattern for timeframe t . PD-DL reconstruction solves a regularized least-squares problem:

$$\arg \min _ { x _ { O V R } } \left \| y _ { O V R } ^ { \Omega _ { t } } - \mathbf E ^ { \Omega _ { t } } x _ { O V R } \right \| _ { 2 } ^ { 2 } + \mathcal { R } \left ( x _ { O V R } \right ),$$

where E Ω t is the multi-coil encoding operator with a sub-sampled Fourier operator that samples Ω t and coils sensitivity maps, and x OVR is the target image with the outer volume excluded. The objective function consists of two terms: a data fidelity (DF) term that ensures consistency with the acquired k-space data and a regularization term R · ( ) that imposes prior constraints on the reconstruction.

A common approach in PD-DL reconstruction is to unroll an iterative algorithm (Aggarwal et al., 2018; Hammernik et al., 2018, 2023; Ramzi et al., 2022; Schlemper et al., 2017; Sun et al., 2016; Yaman et al., 2020a; Zhu et al., 2023) to solve (6) over a fixed number of iterations. The proximal operator for R · ( ) is implicitly modeled using a neural network, while the DF term weights are learned during end-to-end training. The unrolled network structure is shown in Fig. 3b-c, and its implementation details are provided in Sec. 4.2.3.

## 3.3 Training of the PD-DL network and effect of sensitivity maps in OVR

Noting that there is no fully-sampled ground-truth available for RT acquisitions, an unsupervised learning method is necessary for training the associated PD-DL reconstruction network (Ak¸ cakaya et al., 2022). To this end, we adopt a self-supervised learning approach known as Self-Supervised learning via Data Undersampling (SSDU) (Yaman et al., 2022, 2020a), which eliminates the need for fully sampled reference data. Specifically, the multimask version of SSDU partitions the acquired k-space data locations, Ω , into multiple disjoint sets (Θ t k t , Λ ) k t K k =1 . The first subsets, Θ k t , are used for the DF term during network training, while the second subsets, Λ k t , are used to define the self-supervised loss. The resulting multi-mask SSDU loss function is given by:

$$\min _ { \gamma } \mathbb { E } \left [ \frac { 1 } { K } \sum _ { k = 1 } ^ { K } \mathcal { L } \left ( y _ { O V R } ^ { \Lambda _ { t } ^ { k } }, \mathbb { E } ^ { \Lambda _ { t } ^ { k } } \left ( g _ { \gamma } ( y _ { O V R } ^ { \Theta _ { t } ^ { k } }, \mathbb { E } ^ { \Theta _ { t } ^ { k } } ) \right ) \right ) \right ],$$

where g γ ( y Θ k t OVR , E Θ k t ) denotes the output of the PD-DL network parameterized by γ , using the input measurements y Θ k t OVR and encoding operator E Θ k t . K is the number of SSDU masks, and L · · ( , ) is the normalized l 1 -l 2 loss function (Knoll et al., 2020).

While this loss may be used naively, additional considerations apply to our OVR scenario. If the outer volume is indeed perfectly removed from y Λ k t OVR , then the corresponding pixels in x OVR are zero. Note that this is a stronger

condition than sparsity in compressed sensing, since the location of the zero coefficients is specified as well. This can be enforced either via masking in the image domain, or in the context of PD-DL, more appropriately through setting the coil sensitivities in the outer volume region to zero in E Λ k t in order to not to affect the learning of the proximal operator. The latter can also be viewed as inverting a lower rank system in the context of SENSE (Pruessmann et al., 1999). We refer to these sensitivity maps as 'masked', conversely, we refer to the unaltered maps as 'full' sensitivity maps.

However, this represents an idealized scenario, as some residual outer volume signal will remain in k-space. If masked sensitivity maps are used, any residual signal must be mapped into the retained pixels of x OVR , potentially introducing artifacts into the ROI, as illustrated in Fig. 4a. Conversely, using full sensitivity maps results in a more challenging reconstruction problem and carries the risk of redistributing the ROI signal into the outer volume, leading to potential signal loss within the ROI, as illustrated in Fig. 4b.

Thus, it is beneficial to combine the strengths of both approaches. To this end, we propose a novel loss function for training a PD-DL network in the OVR scenario. As noted, using masked sensitivities carries an inherent risk of residual outer volume signal within the ROI, which cannot be reversed. Therefore, we opt to use full sensitivity maps for the final reconstruction. Nonetheless, the masked sensitivity maps are used as an additional term during training to ensure consistency in the ROI signal. In particular, we first train a PD-DL network for OVR k-space data using masked sensitivity maps with the loss function in (7). Let x masked OVR denote the reconstructed images obtained from this network. To avoid issues related to signal loss by naively using the full sensitivity maps, we introduce a loss function term that encourages consistency between reconstructions obtained with masked and full sensitivity maps within the ROI:

$$\min _ { \gamma } \mathbb { E } \left [ \frac { 1 } { K } & \sum _ { k = 1 } ^ { K } \mathcal { L } \left ( y _ { O V R } ^ { \Lambda _ { t } ^ { k } }, \mathbb { E } ^ { \Lambda _ { t } ^ { k } } \left ( g _ { \gamma } ( y _ { O V R } ^ { \Theta _ { t } ^ { k } }, \mathbb { E } ^ { \Theta _ { t } ^ { k } } ) \right ) \right ) \right ] \\ & + \lambda \mathcal { L } \left ( x _ { O V R } ^ { \ m a s k e d }, g _ { \gamma } ( y _ { O V R } ^ { \Omega _ { t } }, \mathbb { E } ^ { \Omega _ { t } } ) \cdot \mathfrak { m } _ { O V R } \right ),$$

where λ is a weight term, and the multi-coil operator E Θ t are defined with full sensitivity maps. This loss function penalizes discrepancies between the two reconstructions, guiding the network to preserve the signal within the ROI, while allowing any residual outer volume signal to be mapped outside the ROI, thereby suppressing artifacts. As shown in Fig. 4c, the updated network effectively eliminates both unwanted artifacts and signal loss in the ROI.

## 4 Experiments and implementation details

## 4.1 Imaging experiments

## 4.1.1 Retrospectively accelerated datasets

Data were acquired from 13 subjects in the left-ventricular short-axis using a bSSFP sequence with an acceleration factor of R = 4 and a Cartesian time-interleaved shifted uniform undersampling pattern (Breuer et al., 2005). The imaging parameters were: field of view (FOV) = 360 × 270 mm , acquired spatial resolution = 2.25 ² × 2.93 mm ² (reconstructed to 2.25 × 2.25 mm ), slice thickness = 8 mm (11 slices), partial Fourier (PF) = 6/8, asymmetric echo ² = 20%, echo time (TE)/repetition time (TR) = 1ms/2.34ms, leading to 17 phase encode (PE) lines per timeframe. To simulate higher acceleration, these datasets were retrospectively undersampled with an acceleration factor of R = 8 by selecting every 8 th line while retaining the k y line nearest to the center of k-space for each timeframe, leading to 9 PE lines per timeframe. Note that the extra central line is retained since the center of the k-space contains the majority of the signal, which can be missed almost entirely at this high acceleration rate for certain timeframes. Practically, the extra line would lead to a mild change of 1 TR ( ∼ 2ms) in temporal resolution.

## 4.1.2 Prospectively accelerated datasets

RT cine MRI data were collected at 3T using a gradient-echo (GRE) sequence with time-interleaved Cartesian sampling in the left-ventricular short-axis. The imaging parameters were: acquired spatial resolution = 1.70 × 2.27 mm , FOV = 300 ² × 300 mm , slice thickness = 5 mm across 12 slices, PF = 6/8, asymmetric echo = 20%, TE = ² 2.4 ms, and TR = 4.7 ms. Prospectively accelerated RT cine data were acquired from 18 subjects (12 for training, 6 for testing) at an acceleration rate of R = 8, with a temporal resolution of 61 ms by acquiring 13 PE lines per timeframe. Additionally, 9 subjects were scanned with an acceleration rate of R = 4 and a temporal resolution of 113 ms (24 PE lines per timeframe) to train the ghosting artifact detection network, as detailed in Sec. 4.2.1.

Finally, for comparison, we also acquired BH ECG-gated segmented cine images on the same subjects. Data were collected from the same short-axis LV slices as the prospective R = 8 scans, with a slice thickness of 5 mm across 12 slices per subject. The imaging parameters were the same as RT cine, except that temporal resolution was 47 ms, and no PF or in-plane acceleration was used.

## 4.2 Implementation details

## 4.2.1 Ghosting artifact detection network

Two separate networks were trained for detecting ghosting artifacts, one for the bSSFP (retrospective) data and one for the GRE (prospective) data. The network architecture (Fig. 3a) was based on a ResNet (Fig. 3c), consisting of input and output convolutional layers and 15 residual blocks (RBs) (Yaman et al., 2022). Each RB contains two convolutional layers, where the first is followed by a rectified linear unit (ReLU) and the second by a constant multiplication layer. All layers use a 3 × 3 kernel size with 64 channels. Its input and output had 8 channels, processing the real and imaginary components of 2D images from 4 timeframes, as described in Sec. 3.1.

The network for retrospective data was trained on 352 slices from 9 subjects, using a learning rate (LR) of 10 -3 over 250 epochs. Data acquired at an acceleration rate of R = 4 were retrospectively undersampled to R = 8, from which composite images were created using 8 subsequent timeframes. Reference ghosting artifact images were generated for each coil by subtracting TGRAPPA (Breuer et al., 2005) reconstructions of the R = 4 data from the composite images. For prospective data, the network was trained on 500 slices from 9 subjects with a learning rate of 10 -3 for 250 epochs. Since no reference ghosting artifacts were available for the R = 8 data, the auxiliary data acquired at R = 4 were used with retrospective undersampling. The ghosting reference was generated using the difference between composite images formed with R = 8 data and TGRAPPA reconstructed R = 4 data on a coil-by-coil basis. In both retrospective and prospective acceleration setups, the training was conducted by minimizing (3).

## 4.2.2 OVR mask prediction network

To estimate m OVR from coil-combined composite images, we trained a U-Net (Ronneberger et al., 2015) to predict heart boundaries. The network was trained using 1200 slices from 12 subjects with the binary cross-entropy loss, LR = 10 -3 for 1000 epochs. Its input was a single coil-combined composite image, and its output was the corresponding binary mask of the same size.

## 4.2.3 PD-DL reconstruction network

For both retrospective and prospective acceleration, we performed all trainings (for x masked OVR and x OVR ) using the PD-DL network described in Demirel et al. (2021); Demirel, Yaman, et al. (2023); Hosseini et al. (2020); Yaman et al. (2020b) with 35 unrolls. The proximal operator for the regularizer was implemented using a ResNet (Gu et al., 2022; Yaman et al., 2020a), with shared parameters across the unrolls (Aggarwal et al., 2018). The input to the unrolled network consisted of zero-filled images generated from outer volume-removed k-space data. We first used masked sensitivity maps and optimized the normalized ℓ 1 -ℓ 2 loss function from Equation 7 to train and generate x masked OVR images. For the final reconstruction, we used full sensitivity maps and a normalized ℓ 1 -ℓ 2 loss with an additional x masked OVR feedback term, as described in (8), with λ = 02. .

For retrospective acceleration, both networks were trained on 352 slices from 9 subjects, and K = 3 masks were used to implement the multi-mask SSDU algorithm (Yaman et al., 2022) using LR = 2 10 · -4 over 200 epochs. The final reconstruction network was tested on 11 slices and 100 timeframes from 3 subjects, with data retrospectively undersampled from R = 4 to R = 8.

For prospective acceleration, both networks were trained on 480 slices from 12 subjects, acquired at R = 8, and K = 3 masks were used in multi-mask SSDU, LR = 2 10 · -4 over 200 epochs. The final reconstruction network was tested on 10 slices and 80 timeframes from 6 subjects.

## 4.2.4 Comparison methods

With retrospective acceleration, TGRAPPA (Breuer et al., 2005) at R = 4 was used as baseline, while we note this is not a true reference due to noise amplification from parallel imaging reconstruction. For prospective acceleration, separate BH ECG-gated segmented cine acquisitions were used as the baseline. Note, since this is a different acquisition, the closest cardiac phase from the BH acquisition is used for display purposes. Furthermore, in all cases, for R = 8, comparisons were made using TGRAPPA as a conventional benchmark, and the same PDDL network in Sec. 4.2.3 without OVR as the fair DL method comparison. For a fair comparison, this non-OVR PD-DL network was trained with the same slices as the proposed OVR PD-DL, but using the standard nonOVR loss function in (7). Notably, all methods presented here are implemented without temporal regularization, ensuring high temporal resolution and a fair comparison.

## 4.3 Cardiac function analysis

Following the reconstructions, cardiac analysis was performed to compare the results of the proposed PD-DL with OVR and baseline reconstructions, TGRAPPA with an acceleration factor of R = 4 for retrospective data, and BH cine for prospective data. Left ventricular (LV) functions were quantified using Segment v4.0 R12067b (Medviso, segment.heiberg.se) (Heiberg et al., 2010). The DL-based segmentation tool was used in the software,

## Composite Image

## Ghosting Artifact (x4)
<|endofpaper|>