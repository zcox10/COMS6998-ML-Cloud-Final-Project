# PIPELINE DEFINITION
# Name: ml-cloud-pipeline
components:
  comp-embed-text-chunks:
    executorLabel: exec-embed-text-chunks
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRUCT
  comp-fine-tune-model:
    executorLabel: exec-fine-tune-model
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRUCT
deploymentSpec:
  executors:
    exec-embed-text-chunks:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - embed_text_chunks
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef embed_text_chunks() -> Dict[str, str]:\n    \"\"\"\n    Generate\
          \ text embeddings on chunked text. Store in GCS\n    \"\"\"\n    # imports\n\
          \    import logging\n    from src.utils.generic_utils import GenericUtils\n\
          \    from src.rag.vector_embeddings import VectorEmbeddings\n\n    # Enable\
          \ logging\n    GenericUtils().configure_component_logging(log_level=logging.INFO)\n\
          \n    VectorEmbeddings().upsert_vector_embeddings()\n    return {\"status\"\
          : \"complete\"}\n\n"
        image: gcr.io/zsc-personal/ml-cloud-pipeline-cpu
    exec-fine-tune-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - fine_tune_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.12.1'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef fine_tune_model() -> Dict[str, str]:\n    \"\"\"\n    Fine-tune\
          \ model\n    \"\"\"\n\n    print(\"model fine tuning\")\n    gcs_uri = \"\
          gs://fine-tuning\"\n    return {\"status\": \"complete\"}\n\n"
        image: gcr.io/zsc-personal/ml-cloud-pipeline-gpu
        resources:
          accelerator:
            resourceCount: '1'
            resourceType: nvidia.com/gpu
pipelineInfo:
  name: ml-cloud-pipeline
root:
  dag:
    tasks:
      embed-text-chunks:
        cachingOptions: {}
        componentRef:
          name: comp-embed-text-chunks
        taskInfo:
          name: embed-text-chunks
      fine-tune-model:
        cachingOptions: {}
        componentRef:
          name: comp-fine-tune-model
        dependentTasks:
        - embed-text-chunks
        taskInfo:
          name: fine-tune-model
schemaVersion: 2.1.0
sdkVersion: kfp-2.12.1
